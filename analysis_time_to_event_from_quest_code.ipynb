{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines\n",
    "from lifelines import CoxPHFitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pickle import loads,dumps\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_survival_data(data_df, id_col, index_time_col, outcome_time_col,\n",
    "                         followup_end_time, followup_max_time_from_index=np.inf,\n",
    "                         censoring_time_col=None):\n",
    "    tmp_data_df = data_df.copy()\n",
    "    if censoring_time_col is None:\n",
    "        censoring_time_col = 'censoring_time_col'\n",
    "        tmp_data_df[censoring_time_col] = np.nan\n",
    "\n",
    "    survival_df = tmp_data_df[[id_col, index_time_col, outcome_time_col, censoring_time_col]].copy()\n",
    "    survival_df['event_time_from_index'] = (survival_df[outcome_time_col] - survival_df[index_time_col])\n",
    "    survival_df['censoring_time_from_index'] = (survival_df[censoring_time_col] - survival_df[index_time_col])\n",
    "    survival_df['followup_end_time_from_index'] = (followup_end_time - survival_df[index_time_col])\n",
    "    survival_df['max_time_from_index'] = followup_max_time_from_index\n",
    "    survival_df['earliest_censoring_time_from_index'] = survival_df[['censoring_time_from_index',\n",
    "                                                                     'followup_end_time_from_index',\n",
    "                                                                     'max_time_from_index']].min(axis=1)\n",
    "    # Seperate into 2 types of people:\n",
    "    # (1) those who have an event before followup_max_time_from_index, followup_end_time_from_index and censoring_time_from_index\n",
    "    idx_event = ( (survival_df[outcome_time_col].notna()) &  \\\n",
    "                  (survival_df['event_time_from_index']<=followup_max_time_from_index) & \\\n",
    "                  (survival_df['event_time_from_index']<=survival_df['earliest_censoring_time_from_index']) )\n",
    "    survival_df.loc[idx_event, 'E'] = 1\n",
    "    survival_df.loc[idx_event, 'T'] = survival_df['event_time_from_index']\n",
    "    survival_df.loc[~idx_event, 'E'] = 0\n",
    "    survival_df.loc[~idx_event, 'T'] = survival_df['earliest_censoring_time_from_index'] \n",
    "    survival_df['E'] = survival_df['E'].astype(int)\n",
    "    survival_df['T'] = survival_df['T'].replace(np.inf, 1000)\n",
    "    survival_df['T'] = survival_df['T'].astype(int)\n",
    "    survival_df.sort_values(['T'], inplace=True)\n",
    "    return survival_df[[id_col, 'E', 'T']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_matrix = pd.read_csv('c:/corona_segal/quest_matrix_outcome_test_new.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = quest_matrix.reset_index().copy()\n",
    "\n",
    "for col in ['visit_date', 'test_date','recover_date']:\n",
    "    data_df.loc[:,col].replace(-9,np.nan, inplace=True)\n",
    "    data_df.loc[:,col] = pd.to_datetime(data_df[col], format='%Y%m%d')\n",
    "\n",
    "MAX_DATE = data_df[['visit_date', 'test_date','recover_date']].max().max()\n",
    "MIN_DATE = data_df[['visit_date', 'test_date','recover_date']].min().min()\n",
    "\n",
    "data_df['pos_test_date'] = data_df['test_date']\n",
    "data_df.loc[(data_df['test_result']!=1), 'pos_test_date'] = np.nan\n",
    "\n",
    "data_df['neg_test_date'] = data_df['test_date']\n",
    "data_df.loc[(data_df['test_result']>0), 'neg_test_date'] = np.nan\n",
    "\n",
    "for col in ['visit_date', 'pos_test_date', 'neg_test_date','recover_date']:\n",
    "    data_df.loc[:,col+'_T'] = (data_df.loc[:,col] -  MIN_DATE).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['test_date_correction'] = (data_df['test_date']-MIN_DATE)/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_to_pos_test_surv_df(data_df, followup_max_time_from_index=21, censoring_time_col=None):  \n",
    "    \n",
    "    surv_df = create_survival_data(data_df,\n",
    "                     id_col='index', index_time_col='visit_date_T', outcome_time_col='pos_test_date_T',\n",
    "                     followup_end_time=(MAX_DATE-MIN_DATE).days, followup_max_time_from_index=21,\n",
    "                                   censoring_time_col=censoring_time_col)\n",
    "    surv_df = surv_df[surv_df['T']>=0]\n",
    "\n",
    "\n",
    "    symp_cols = ['chom_375_379', 'chom_38_40',\n",
    "           'chom_up_to_374', 'symp_ayefut', 'symp_bchilot_akahot', 'symp_bilbul',\n",
    "           'symp_godesh_nazelet', 'symp_keev_garon', 'symp_keev_rosh',\n",
    "           'symp_keev_shririm', 'symp_kotzer_neshima', 'symp_none', 'symp_other',\n",
    "           'symp_shilshul', 'symp_shiul', 'symp_shiul_leicha', 'symp_shiul_yavesh',\n",
    "           'symp_taam_reach', 'symp_zmarmoret','visit_date','time_to_test']\n",
    "\n",
    "    surv_df = surv_df.merge(data_df[['id','index', 'age', 'gender','id_disease','test_date_correction','test_result']+symp_cols], on='index', how='left')\n",
    "    \n",
    "    return surv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_df = prepare_time_to_pos_test_surv_df(data_df, followup_max_time_from_index=21, censoring_time_col='neg_test_date_T')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_count = surv_df[['id','age']].groupby(['id']).size().reset_index(name=\"count_id\")\n",
    "df_id_count['weight'] = 1/df_id_count['count_id']\n",
    "surv_df['weight_by_n_quest'] = surv_df[['id']].merge(df_id_count[['id','weight']], on='id', how='left')['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_df['weight_1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index_per_id =  surv_df.sample(frac=1.0).groupby('id').head(1)\n",
    "random_index_per_id['random_per_id']=1\n",
    "surv_df['rand_by_id'] = surv_df.merge(random_index_per_id[['index','random_per_id']], on='index', how='left')['random_per_id']\n",
    "surv_df['rand_by_id'] = surv_df['rand_by_id'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_per_id = surv_df.sort_values('visit_date').groupby('id').first().reset_index()\n",
    "first_per_id['first_per_id']=1\n",
    "surv_df['first_per_id'] = surv_df.merge(first_per_id[['index','first_per_id']], on='index', how='left')['first_per_id']\n",
    "surv_df['first_per_id'] = surv_df['first_per_id'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_per_id = surv_df.sort_values('visit_date',ascending=False).groupby('id').first().reset_index()\n",
    "last_per_id['last_per_id']=1\n",
    "surv_df['last_per_id'] = surv_df.merge(last_per_id[['index','last_per_id']], on='index', how='left')['last_per_id']\n",
    "surv_df['last_per_id'] = surv_df['last_per_id'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "kmf = KaplanMeierFitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_df_tested =  surv_df[surv_df['test_result']>=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaplan Meier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " symp_cols = ['chom_375_379', 'chom_38_40',\n",
    "           'chom_up_to_374', 'symp_ayefut', 'symp_bchilot_akahot', 'symp_bilbul',\n",
    "           'symp_godesh_nazelet', 'symp_keev_garon', 'symp_keev_rosh',\n",
    "           'symp_keev_shririm', 'symp_kotzer_neshima', 'symp_none', 'symp_other',\n",
    "           'symp_shilshul', 'symp_shiul', 'symp_shiul_leicha', 'symp_shiul_yavesh',\n",
    "           'symp_taam_reach', 'symp_zmarmoret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_km(data_df, use_weight, use_quest , write_to_pickle,pop):  \n",
    "    \n",
    "    pickle_name = 'c:/corona_segal/'+folder+'/quest_'+ pop + '_km_outcome_pos_test_' + use_weight + '_quest_' + use_quest + '_pickle'\n",
    "    \n",
    "    if (write_to_pickle==1) :\n",
    "        file = open(pickle_name,'wb')\n",
    "    \n",
    "    \n",
    "    if (use_quest=='first'):\n",
    "        surv_df = data_df[data_df['first_per_id']==1]\n",
    "    elif (use_quest=='last'):\n",
    "        surv_df = data_df[data_df['last_per_id']==1]\n",
    "    elif (use_quest=='random'):\n",
    "        surv_df = data_df[data_df['rand_by_id']==1]\n",
    "    else:\n",
    "        surv_df = data_df\n",
    "        \n",
    "    if (use_weight=='weight_by_id_count'):\n",
    "        vec_weight = data_df[['weight_by_n_quest']]\n",
    "    else:\n",
    "        vec_weight = data_df[['weight_1']]                             \n",
    "        \n",
    "    \n",
    "    fig, axes = plt.subplots(5,4, figsize=(18,20), dpi=100)\n",
    "    for i, symp_col in enumerate(symp_cols):\n",
    "        ax = axes[i//4, i%4]\n",
    "\n",
    "        if (use_weight=='weight_by_id_count'):\n",
    "            kmf_0 = KaplanMeierFitter()\n",
    "            kmf_0.fit(surv_df.loc[surv_df[symp_col]==0, 'T'], surv_df.loc[surv_df[symp_col]==0, 'E'], label=f'{symp_col}=0', weights=surv_df.loc[surv_df[symp_col]==0, 'weight_by_n_quest'])\n",
    "            kmf_0.plot(ax=ax)\n",
    "\n",
    "            kmf_1 = KaplanMeierFitter()\n",
    "            kmf_1.fit(surv_df.loc[surv_df[symp_col]==1, 'T'], surv_df.loc[surv_df[symp_col]==1, 'E'], label=f'{symp_col}=1', weights=surv_df.loc[surv_df[symp_col]==1, 'weight_by_n_quest'])\n",
    "            kmf_1.plot(ax=ax)\n",
    "        else:\n",
    "            kmf_0 = KaplanMeierFitter()\n",
    "            kmf_0.fit(surv_df.loc[surv_df[symp_col]==0, 'T'], surv_df.loc[surv_df[symp_col]==0, 'E'], label=f'{symp_col}=0')\n",
    "            kmf_0.plot(ax=ax)\n",
    "\n",
    "            kmf_1 = KaplanMeierFitter()\n",
    "            kmf_1.fit(surv_df.loc[surv_df[symp_col]==1, 'T'], surv_df.loc[surv_df[symp_col]==1, 'E'], label=f'{symp_col}=1')\n",
    "            kmf_1.plot(ax=ax)\n",
    "        \n",
    "        if (write_to_pickle==1) :\n",
    "            pickle.dump(kmf_0,file)\n",
    "            pickle.dump(kmf_1,file)    \n",
    "\n",
    "        ax.legend()\n",
    "        #fig_name = 'c:/corona_segal/quest_km_outcome_pos_test_' + 'weight_' + use_weight + '_quest_' + use_quest\n",
    "        #plt.savefig(fig_name)\n",
    "    \n",
    "    if (write_to_pickle==1) :\n",
    "        file.close()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_km(surv_df_tested, use_weight='weight_1', use_quest='all' , write_to_pickle=1,pop='tested')\n",
    "run_km(surv_df_tested, use_weight='weight_by_id_count', use_quest='all' , write_to_pickle=1,pop='tested')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vec = surv_df['test_result']>=0\n",
    "y_vec= y_vec*1\n",
    "x_mat = surv_df[symp_cols + ['age','gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from causallib.datasets import load_nhefs\n",
    "%matplotlib inline\n",
    "from causallib.datasets import load_nhefs\n",
    "from causallib.estimation import IPW\n",
    "from causallib.evaluation import PropensityEvaluator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "learner = LogisticRegression(solver=\"liblinear\")\n",
    "ipw = IPW(learner)\n",
    "ipw.fit(x_mat, y_vec)\n",
    "ipw_vec = ipw.compute_weights(x_mat, y_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_name_ipw = 'c:/corona_segal/'+folder + 'time_to_outcome_predict_test_ipw_pickle'\n",
    "file_ipw = open(pickle_name_ipw,'wb')\n",
    "pickle.dump(ipw,file_ipw)\n",
    "file_ipw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "plots=[\"roc_curve\", \"pr_curve\", \"weight_distribution\", \n",
    "       \"calibration\", \"covariate_balance_love\", \"covariate_balance_slope\"]\n",
    "metrics = {\"roc_auc\": metrics.roc_auc_score,\n",
    "           \"avg_precision\": metrics.average_precision_score,}\n",
    "evaluator = PropensityEvaluator(ipw)\n",
    "results = evaluator.evaluate_cv(x_mat, y_vec, y_vec, \n",
    "                                plots=plots, metrics_to_evaluate=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_df['ipw'] = ipw_vec\n",
    "surv_df['ipw_and_weight_sample']=ipw_vec*surv_df['weight_by_n_quest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cox(data_df, use_weight, use_quest , write_to_pickle,pop):  \n",
    "    \n",
    "    pickle_name = 'c:/corona_segal/'+folder+'/quest_'+ pop + '_cox_outcome_pos_test_' + use_weight + '_quest_' + use_quest + '_pickle'\n",
    "    summary_name = 'c:/corona_segal/'+folder+'/quest_'+ pop + '_cox_outcome_pos_test_' + use_weight + '_quest_' + use_quest + '_summary'\n",
    "    \n",
    "    if (write_to_pickle==1) :\n",
    "        file = open(pickle_name,'wb')\n",
    "    \n",
    "    \n",
    "    if (use_quest=='first'):\n",
    "        surv_dfxx = data_df[data_df['first_per_id']==1]\n",
    "    elif (use_quest=='last'):\n",
    "        surv_dfxx = data_df[data_df['last_per_id']==1]\n",
    "    elif (use_quest=='random'):\n",
    "        surv_dfxx = data_df[data_df['rand_by_id']==1]\n",
    "    else:\n",
    "        surv_dfxx = data_df\n",
    "        \n",
    "    if (use_weight=='weight_by_id_count'):\n",
    "        vec_weight = data_df[['weight_by_n_quest']]\n",
    "    else:\n",
    "        vec_weight = data_df[['weight_1']]                             \n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "    fig, axes = plt.subplots(5,4, figsize=(18,20), dpi=100)\n",
    "    for i, symp_col in enumerate(symp_cols):\n",
    "        ax = axes[i//4, i%4]\n",
    "\n",
    "        if (use_weight=='weight_by_id_count'):\n",
    "            cph = CoxPHFitter()\n",
    "            cph.fit(surv_dfxx[['T', 'E', 'age', 'gender','id_disease','test_date_correction','ipw_and_weight_sample', symp_col]],robust=False, duration_col='T', event_col='E', step_size=0.01, weights_col='ipw_and_weight_sample')\n",
    "        else:\n",
    "            cph = CoxPHFitter()\n",
    "            cph.fit(surv_dfxx[['T', 'E', 'age', 'gender','id_disease','test_date_correction','ipw', symp_col]],robust=False, duration_col='T', event_col='E', step_size=0.01, weights_col='ipw')\n",
    "        \n",
    "        a = cph.summary\n",
    "        if (i==0):\n",
    "            orig_summary = a\n",
    "        else:\n",
    "            orig_summary = pd.concat([orig_summary,a])            \n",
    "        \n",
    "        \n",
    "        cph.plot_partial_effects_on_outcome(covariates=symp_col, values=[0,1], cmap='coolwarm', ax=ax)\n",
    "        \n",
    "        if (write_to_pickle==1) :\n",
    "            pickle.dump(cph,file)\n",
    "\n",
    "        #fig_name = 'c:/corona_segal/quest_cox_outcome_pos_test_' + use_weight + '_quest_' + use_quest\n",
    "        #plt.savefig(fig_name)\n",
    "    \n",
    "    orig_summary.to_csv(summary_name)\n",
    "    \n",
    "    if (write_to_pickle==1) :\n",
    "        file.close()\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_df_tested2 =  surv_df[surv_df['test_result']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cox(surv_df_tested2, use_weight='weight_1', use_quest='all' , write_to_pickle=1,pop='tested')\n",
    "run_cox(surv_df_tested2, use_weight='weight_by_id_count', use_quest='all' , write_to_pickle=1,pop='tested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
